{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676ac49f",
   "metadata": {},
   "source": [
    "# Sales Channel Prediction Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906374c",
   "metadata": {},
   "source": [
    "## Prelude:\n",
    "        In any firm sales form the bread and butter to an organization. Sales is one of the factors and quite crucial in         determining the survival and prosperity of an organization. So continuing our discussion, this project is regarding the         marketing mix an organization uses to boost sales. For this task, one analyst has to determine the perfect ratio of     media channels engaged by the firm to maximise the sales by allocating optimum budget to each medium of communication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea74ee",
   "metadata": {},
   "source": [
    "### About the Independent Variables:\n",
    " We are given three continuous variables which are as follows:\n",
    " \n",
    " 1. TV: This variable talks about expenditure in Television advertisements\n",
    " 2. Radio: This variable talks about expenditure in Radio advertisements\n",
    " 3. Newspaper: This variable talks about expenditure in Newspaper advertisements\n",
    "\n",
    "### About the Dependent Variable:\n",
    " \n",
    " Sales: This continuous variable talks about the sales generated by employing the above independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15bff2d",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "    Build a best-fit prediction model for allocation of budget in media channels to gain optimum sales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac83908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "\n",
    "# Importing fundamental packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.core.interactiveshell import InteractiveShell        ## To display multiple outputs\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pyforest            \n",
    "\n",
    "## For visualization\n",
    "import matplotlib.pyplot as plt                                         \n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "## Data Pre-Processing Packages\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_blobs\n",
    "%pylab inline\n",
    "from pylab import *\n",
    "import random as pyrandom\n",
    "from scipy.spatial.distance import cdist\n",
    "matplotlib.rc(\"image\",cmap=\"gray\")\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "\n",
    "## To create copy of data\n",
    "import copy\n",
    "\n",
    "## Pipeline Packages\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# For Building Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Evaluation Metrics Packages\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import f\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Saving the model\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab352ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(link):\n",
    "    global data\n",
    "\n",
    "    data=pd.read_csv(link)\n",
    "    \n",
    "    data=pd.DataFrame(data)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a21206",
   "metadata": {},
   "outputs": [],
   "source": [
    "read(link=\"Advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe220af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(mydata):                                    # Defining function\n",
    "    \n",
    "    pd.set_option(\"display.max_rows\", None)         # to display all rows\n",
    "    pd.set_option(\"display.max_columns\", None)       #to display all columns\n",
    "    \n",
    "    print(mydata.head())                              # to display first 10 records\n",
    "    print(\"\\n\")                               \n",
    "    print(mydata.tail())                              # to display last 10 records\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(mydata.info())                               # to understand attributes of the data\n",
    "    \n",
    "    print(mydata.describe())                          # to get descriptive statistics\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    print(\"Skewness for the data\",\"\\n\",mydata.skew())       # to get skewness of the data, skewness=0 for normal distribution\n",
    "    print(\"\\n\")\n",
    "    print(\"Kurosis for the data\",\"\\n\",mydata.kurtosis() )            # to get kutosis, kurtosis <=3 for normal distribution\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    sns.pairplot(mydata, kind='scatter', diag_kind='kde')                       # to represent data graphically\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")    \n",
    "    \n",
    "    plt.figure(figsize=(10,10))                      # plotting heat map to check correlation\n",
    "    sns.heatmap(mydata.corr(method = \"pearson\"), annot = True)\n",
    "    print(\"\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651fea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda(mydata=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9df657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier(mydata):                        # Outlier Plotting\n",
    "    for i in mydata.columns:\n",
    "        fig = px.box(mydata, y= i, width=600, height=400, title=i, template=\"plotly_dark\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier(mydata=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ab331",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogram for all the variables using plotly_express by 'quality'\n",
    "\n",
    "for i in data.columns:\n",
    "    fig = px.histogram(data, x= i, histfunc = \"count\", color = \"sales\", \n",
    "                       width=1000, height=800, title = \"Histogram for \" + i, \n",
    "                       template=\"plotly_dark\", cumulative=True)\n",
    "\n",
    "    fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting qq plot\n",
    "\n",
    "for i in data.columns:\n",
    "    fig = sm.qqplot(data[i])\n",
    "\n",
    "    fig.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4a9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot for TV and Sales\n",
    "\n",
    "sns.scatterplot(x=\"TV\",y=\"sales\",data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878cb2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot for Radio and Sales\n",
    "\n",
    "sns.scatterplot(x=\"radio\",y=\"sales\",data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot for Newspaper and Sales\n",
    "sns.scatterplot(x=\"newspaper\",y=\"sales\",data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2662978",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features= pd.DataFrame(data.drop([\"sales\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vif(data):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = data.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13675e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_vif(data=data.drop([\"sales\"],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b28a9",
   "metadata": {},
   "source": [
    "## Findings:\n",
    "1. There are no missing data in the dataset\n",
    "\n",
    "2. There are 200 rows and 5 columns\n",
    "\n",
    "3. The data follows a normal distribution\n",
    "\n",
    "4. The \"unnamed:0\" column happens to be an identifier as it has only serial number as values and has neglible correlation          suggesting no significance to our target variable. Therefore, it can be dropped from our dataset.\n",
    "\n",
    "5.  Average expenditure on TV ads is 147.04 and average sales generated is 12089.37\n",
    "\n",
    "6.  Average expenditure on Radio ads is 23.26 and average sales generated is 3021.92\n",
    "\n",
    "7.  Average expenditure on Newspaper ads is 30.55 and average sales generated is 3874.63\n",
    "\n",
    "8. Average sales generated because of media channels is 14.02\n",
    "\n",
    "9. Newspaper has outliers\n",
    "\n",
    "10. There is no issue of multi-collinearity in the data\n",
    "\n",
    "11. Cumulative effect of spending on media results in increasing sales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a4ed2f",
   "metadata": {},
   "source": [
    "## Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8a5ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of dataset for cleaning and model building purpose\n",
    "\n",
    "data2= copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd66d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2= data.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c50859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating outliers\n",
    "q1 = data2.quantile(.25)    # first quartile\n",
    "q3 = data2.quantile(.75)    # third quartile\n",
    "iqr = q3 - q1\n",
    "\n",
    "for i in data2.drop(['sales'],axis=1).columns:\n",
    "    data2['newspaper'] = np.where(data2[i] > (data2[i].quantile(0.75) + (data2[i].quantile(0.75) - data2[i].quantile(0.25))*1.5),\n",
    "                           (data2[i].quantile(0.75) + (data2[i].quantile(0.75) - data2[i].quantile(0.25))*1.5),\n",
    "                          np.where(data2[i] < (data2[i].quantile(0.25) - (data2[i].quantile(0.75) - data2[i].quantile(0.25))*1.5),\n",
    "                           (data2[i].quantile(0.25) - (data2[i].quantile(0.75) - data2[i].quantile(0.25))*1.5),data2[i]))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier(mydata=data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5504801",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features2=data2.drop([\"sales\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6cf7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB Scan\n",
    "\n",
    "# Data creation\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "data_features, labels_true = make_blobs(n_samples=50, centers=centers, cluster_std=0.4,\n",
    "                            random_state=1)  # generate sample blobs\n",
    "X = StandardScaler().fit_transform(data_features2)\n",
    "X[:5]\n",
    "\n",
    "# DBSCAN\n",
    "db = DBSCAN(eps=0.5, min_samples=3).fit(X)\n",
    "\n",
    "labels = db.labels_  # similar to the model.fit() method, it gives the labels of the clustered data\n",
    "\n",
    "print (labels)\n",
    "\n",
    "# Setting Length of labels\n",
    "len(set(labels))\n",
    "\n",
    "1 if -1 in labels else 0\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0) # the label -1 is considered as noise by the DBSCAN algorithm\n",
    "n_noise_ = list(labels).count(-1)  # calculating the number of noises (-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "# Below code is for showcasing in diagram. Nothing related to model building\n",
    "\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)  # creating an array of true and false as the same size as db.labels\n",
    "\n",
    "core_samples_mask[db.core_sample_indices_] = True  # setting the indices of the core regions to True\n",
    "# Black  is used for noise.\n",
    "unique_labels = set(labels)  # identifying all the unique labels/clusters\n",
    "\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]  # creating the list of colours, generating the colourmap\n",
    "\n",
    "\n",
    "\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    \n",
    "    \n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)   # assigning class members for each class\n",
    "    \n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask] # creating the list of points for each class\n",
    "    \n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "    \n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask] # creating the list of noise points\n",
    "    \n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='b', markersize=14)\n",
    "    \n",
    "    \n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()\n",
    "\n",
    "# Finding counts in each cluster\n",
    "np.unique(labels, return_counts=True)\n",
    "\n",
    "# Selecting only noises\n",
    "noises = X[labels == 4]\n",
    "\n",
    "print (noises)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59d195",
   "metadata": {},
   "source": [
    "There are no outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features2= pd.DataFrame(data2.drop([\"sales\"], axis=1))\n",
    "data_label=pd.DataFrame(data2[\"sales\"])\n",
    "print(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61347a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing skewness using Yeo-Johnson\n",
    "# Removing data skewness\n",
    "pt = PowerTransformer(method='yeo-johnson',standardize='True')\n",
    "    \n",
    "data_noskew= pt.fit_transform(data_features2.values)\n",
    "data_noskewtab= pd.DataFrame(data_noskew)\n",
    "data_noskewtab.columns = ['TV', 'radio', 'newspaper']\n",
    "\n",
    "print(data_noskewtab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eaf88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean=pd.DataFrame(data_noskewtab)\n",
    "print(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8201a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=pd.DataFrame()\n",
    "data_final=pd.concat([data_clean,data_label], axis=1)\n",
    "print(data_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72613ca0",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd97ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split (data,target):\n",
    "    data_reset_index = data.reset_index(drop=True)\n",
    "# Data split\n",
    "    global x\n",
    "    global y\n",
    "    global x_train\n",
    "    global y_train\n",
    "    global x_test\n",
    "    global y_test\n",
    "# Segregate Feature & Target Variables\n",
    "    x = data_reset_index.drop(target, axis=1)\n",
    "    y = data_reset_index[target]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.3, random_state=3)\n",
    "    \n",
    "    print(x_train.info())\n",
    "    (\"\\n\")\n",
    "    print(x_test.info())\n",
    "    (\"\\n\")\n",
    "    print(y_train.shape)\n",
    "    (\"\\n\")\n",
    "    print(y_test.shape)\n",
    "    (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac73750",
   "metadata": {},
   "outputs": [],
   "source": [
    "split(data=data_final,\n",
    "      target=\"sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78db251",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a036056",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_1= StandardScaler()\n",
    "scale_2= MinMaxScaler()\n",
    "scale_3= RobustScaler()\n",
    "model= LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c410924",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline([\n",
    "    ('Scale',scale_1),\n",
    "    ('model',model),\n",
    "])    \n",
    "pipe2 = Pipeline([\n",
    "    ('Scale',scale_2),\n",
    "    ('model',model),\n",
    "])\n",
    "pipe3 = Pipeline([\n",
    "    ('Scale',scale_3),\n",
    "    ('model',model),  \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function Name \n",
    "def pre_process(data, pipe):\n",
    "\n",
    "# Pipe.fit, pipe.predict and accuracy\n",
    "    \n",
    "    pipe.fit(x_train,y_train)\n",
    "    \n",
    "    y_pred = pipe.predict(x_test)\n",
    "    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_pred, y_test))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af352bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process(data= data2,\n",
    "           pipe= pipe1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819bc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process(data= data2,\n",
    "           pipe= pipe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process(data= data2,\n",
    "           pipe= pipe3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f6b3bb",
   "metadata": {},
   "source": [
    "Lets go ahead with Robust scaler as its score is maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f3e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar= RobustScaler()\n",
    "scalar.fit(x_train)\n",
    "x_trainsc =  scalar.transform(x_train)\n",
    "x_testsc  =  scalar.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcfa8b6",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50390105",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9795ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_trainsc, y_train)\n",
    "\n",
    "\n",
    "model = sm.OLS(y_train, x_trainsc).fit()\n",
    "\n",
    "\n",
    "y_pred = model.predict(x_testsc)\n",
    "\n",
    "print(\"Linear Regression Train Score: \", lr.score(x_trainsc , y_train))\n",
    "\n",
    "print(\"Linear Regression Test Score: \", lr.score(x_testsc , y_test))\n",
    "\n",
    "print('Mean Absolute Error:', np.round(metrics.mean_absolute_error(y_test, y_pred),2))  \n",
    "print('Mean Squared Error:', np.round(metrics.mean_squared_error(y_test, y_pred),2))  \n",
    "print('Root Mean Squared Error:', np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)),2))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(lr, n_features_to_select=6)             \n",
    "rfe = rfe.fit(x_trainsc, y_train)\n",
    "\n",
    "r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "scores = cross_val_score(lr, x_trainsc, y_train, scoring='r2', cv=5)\n",
    "scores   \n",
    "\n",
    "# create a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "scores = cross_val_score(lr, x_trainsc, y_train, scoring='r2', cv=folds)\n",
    "scores  \n",
    "\n",
    "scores = cross_val_score(lr, x_trainsc, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ea748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-1: create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'n_features_to_select': list(range(1, 14))}]\n",
    "\n",
    "\n",
    "# step-3: perform grid search\n",
    "# 3.1 specify model\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_trainsc, y_train)\n",
    "rfe = RFE(lm)             \n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'r2', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "grid_result= model_cv.fit(x_trainsc, y_train)   \n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebb958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model\n",
    "n_features_optimal = 3\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_trainsc, y_train)\n",
    "\n",
    "rfe = RFE(lm, n_features_to_select=n_features_optimal)             \n",
    "rfe = rfe.fit(x_trainsc, y_train)\n",
    "\n",
    "# predict prices of X_test\n",
    "y_pred = lm.predict(x_testsc)\n",
    "r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "print(r2)\n",
    "\n",
    "print(\"Linear Regression Train Score: \", lm.score(x_trainsc , y_train))\n",
    "\n",
    "print(\"Linear Regression Test Score: \", lm.score(x_testsc , y_test))\n",
    "\n",
    "print('Mean Absolute Error:', np.round(metrics.mean_absolute_error(y_test, y_pred),2))  \n",
    "print('Mean Squared Error:', np.round(metrics.mean_squared_error(y_test, y_pred),2))  \n",
    "print('Root Mean Squared Error:', np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3216817c",
   "metadata": {},
   "source": [
    "Lasso Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fdf3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_001 = Lasso(alpha = 0.5 , max_iter=10e5)\n",
    "\n",
    "lasso_001.fit(x_trainsc , y_train)\n",
    "\n",
    "\n",
    "y_pred_lasso = lasso_001.predict(x_testsc)\n",
    "\n",
    "print(\"LASSO Regression Train Score: \", lasso_001.score(x_trainsc , y_train))\n",
    "\n",
    "print(\"LASSO Regression Test Score: \", lasso_001.score(x_testsc , y_test))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error:', np.round(metrics.mean_absolute_error(y_test, y_pred_lasso),2))  \n",
    "print('Mean Squared Error:', np.round(metrics.mean_squared_error(y_test, y_pred_lasso),2))  \n",
    "print('Root Mean Squared Error:', np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_lasso)),2))\n",
    "\n",
    "\n",
    "coeff_used_002 = np.sum(lasso_001.coef_ != 0)\n",
    "\n",
    "print(\"Coefficient used:\",\"\\n\",coeff_used_002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(lasso_001, n_features_to_select=6)             \n",
    "rfe = rfe.fit(x_trainsc, y_train)\n",
    "\n",
    "r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "scores = cross_val_score(lasso_001, x_trainsc, y_train, scoring='r2', cv=5)\n",
    "scores   \n",
    "\n",
    "# create a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "scores = cross_val_score(lasso_001, x_trainsc, y_train, scoring='r2', cv=folds)\n",
    "scores  \n",
    "\n",
    "scores = cross_val_score(lasso_001, x_trainsc, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-1: create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'alpha': range(0, 1), 'random_state':range(1, 10,1), 'selection': ['cyclic', 'random'] }]\n",
    "\n",
    "# step-3: perform grid search\n",
    "# 3.1 specify model\n",
    "lasso_001 = Lasso()\n",
    "lasso_001.fit(x_trainsc , y_train)\n",
    "rfe = RFE(lasso_001)             \n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = lasso_001, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "grid_result= model_cv.fit(x_trainsc, y_train)   \n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_001 = Lasso(alpha = 0 , selection='random', random_state=3)\n",
    "\n",
    "lasso_001.fit(x_trainsc , y_train)\n",
    "\n",
    "\n",
    "y_pred_lasso = lasso_001.predict(x_testsc)\n",
    "\n",
    "print(\"LASSO Regression Train Score: \", lasso_001.score(x_trainsc , y_train))\n",
    "\n",
    "print(\"LASSO Regression Test Score: \", lasso_001.score(x_testsc , y_test))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error:', np.round(metrics.mean_absolute_error(y_test, y_pred_lasso),2))  \n",
    "print('Mean Squared Error:', np.round(metrics.mean_squared_error(y_test, y_pred_lasso),2))  \n",
    "print('Root Mean Squared Error:', np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_lasso)),2))\n",
    "\n",
    "\n",
    "coeff_used_002 = np.sum(lasso_001.coef_ != 0)\n",
    "\n",
    "print(\"Coefficient used:\",\"\\n\",coeff_used_002)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661da4d",
   "metadata": {},
   "source": [
    "Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef389b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rr = Ridge(alpha = 0.5)                                                   # alpha = regularization hyper-parameter\n",
    "\n",
    "rr.fit(x_trainsc, y_train)\n",
    "\n",
    "\n",
    "y_pred_rr = rr.predict(x_testsc)\n",
    "\n",
    "print(\"Ridge Regression Train Score: \", rr.score(x_trainsc, y_train))\n",
    "print(\"Ridge Regression Test Score: \", rr.score(x_testsc, y_test))\n",
    "print(\"\\n\")\n",
    "print('Mean Absolute Error:', np.round(metrics.mean_absolute_error(y_test, y_pred_rr),2))  \n",
    "print('Mean Squared Error:', np.round(metrics.mean_squared_error(y_test, y_pred_rr),2))\n",
    "print('Root Mean Squared Error:', np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_rr)),2))\n",
    "\n",
    "\n",
    "\n",
    "coeff_used_001 = np.sum(rr.coef_ != 0)\n",
    "\n",
    "print(\"Coefficient used:\",\"\\n\",coeff_used_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8decce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(rr, n_features_to_select=6)             \n",
    "rfe = rfe.fit(x_trainsc, y_train)\n",
    "\n",
    "r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "scores = cross_val_score(rr, x_trainsc, y_train, scoring='r2', cv=5)\n",
    "scores   \n",
    "\n",
    "# create a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "scores = cross_val_score(lasso_001, x_trainsc, y_train, scoring='r2', cv=folds)\n",
    "scores  \n",
    "\n",
    "scores = cross_val_score(lasso_001, x_trainsc, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d846253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-1: create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'alpha': list(range(0, 1)),'normalize':[True, False],\n",
    "                 'random_state':list(range(0, 10)), 'tol': list(range(-100, 100, 50)), \n",
    "                 'solver': ['auto', 'svd','cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']}]\n",
    "\n",
    "\n",
    "# step-3: perform grid search\n",
    "\n",
    "# 3.1 specify model\n",
    "rr = Ridge()\n",
    "rr.fit(x_trainsc, y_train)\n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = rr,\n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds,\n",
    "                        verbose=1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "grid_result= model_cv.fit(x_trainsc, y_train)   \n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "\n",
    "print('Best Params: ', grid_result.best_params_)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ed0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = Ridge(alpha = 0, normalize= True, random_state= 1, solver= 'sag', tol= 50)                                                   # alpha = regularization hyper-parameter\n",
    "\n",
    "rr.fit(x_trainsc, y_train)\n",
    "\n",
    "\n",
    "y_pred_rr = rr.predict(x_testsc)\n",
    "\n",
    "print(\"Ridge Regression Train Score: \", rr.score(x_trainsc, y_train))\n",
    "print(\"Ridge Regression Test Score: \", rr.score(x_testsc, y_test))\n",
    "print(\"\\n\")\n",
    "print('Mean Absolute Error:', np.round(metrics.mean_absolute_error(y_test, y_pred_rr),2))  \n",
    "print('Mean Squared Error:', np.round(metrics.mean_squared_error(y_test, y_pred_rr),2))\n",
    "print('Root Mean Squared Error:', np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_rr)),2))\n",
    "\n",
    "\n",
    "\n",
    "coeff_used_001 = np.sum(rr.coef_ != 0)\n",
    "\n",
    "print(\"Coefficient used:\",\"\\n\",coeff_used_001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e3c026",
   "metadata": {},
   "source": [
    "Elastic Net Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2518c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_elastic = ElasticNet(alpha = 0.5)\n",
    "\n",
    "lm_elastic.fit(x_trainsc, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_elastic = lm_elastic.predict(x_testsc)\n",
    "\n",
    "\n",
    "print(\"Elastic Net Train Score: \", lm_elastic.score(x_trainsc , y_train))\n",
    "\n",
    "print(\"Elastic Net Test Score: \", lm_elastic.score(x_testsc , y_test))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error: \\n', np.round(metrics.mean_absolute_error(y_test, y_pred_elastic),2)) \n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print('Mean Squared Error: \\n', np.round(metrics.mean_squared_error(y_test, y_pred_elastic),2))\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print('Root Mean Squared Error: \\n', np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_elastic)),2))\n",
    "\n",
    "coeff_used_003 = np.sum(lm_elastic.coef_ != 0)\n",
    "\n",
    "print(\"Coefficient used:\",\"\\n\",coeff_used_003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d78d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(lm_elastic, n_features_to_select=6)             \n",
    "rfe = rfe.fit(x_trainsc, y_train)\n",
    "\n",
    "r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "scores = cross_val_score(rr, x_trainsc, y_train, scoring='r2', cv=5)\n",
    "scores   \n",
    "\n",
    "# create a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "scores = cross_val_score(lasso_001, x_trainsc, y_train, scoring='r2', cv=folds)\n",
    "scores  \n",
    "\n",
    "scores = cross_val_score(lasso_001, x_trainsc, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe788f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-1: create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'alpha': list(range(0, 1)),'fit_intercept': [True, False],\n",
    "                 'normalize':[True, False],\n",
    "                 'random_state':list(range(0, 10)), 'tol': list(range(-100, 100, 50)), \n",
    "                 'selection': ['cyclic', 'random']}]\n",
    "\n",
    "\n",
    "# step-3: perform grid search\n",
    "# 3.1 specify model\n",
    "lm_elastic = ElasticNet()\n",
    "\n",
    "lm_elastic.fit(x_trainsc, y_train)\n",
    "            \n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = lm_elastic,\n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds,\n",
    "                        verbose=1,\n",
    "                        return_train_score=True)\n",
    "    \n",
    "\n",
    "# fit the model\n",
    "grid_result= model_cv.fit(x_trainsc, y_train)   \n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_elastic = ElasticNet(alpha= 0, fit_intercept= True, normalize= True, random_state= 0, selection='random', tol= 50)\n",
    "\n",
    "lm_elastic.fit(x_trainsc, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_elastic = lm_elastic.predict(x_testsc)\n",
    "\n",
    "\n",
    "print(\"Elastic Net Train Score: \", lm_elastic.score(x_trainsc , y_train))\n",
    "\n",
    "print(\"Elastic Net Test Score: \", lm_elastic.score(x_testsc , y_test))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error: \\n', np.round(metrics.mean_absolute_error(y_test, y_pred_elastic),2)) \n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print('Mean Squared Error: \\n', np.round(metrics.mean_squared_error(y_test, y_pred_elastic),2))\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print('Root Mean Squared Error: \\n', np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_elastic)),2))\n",
    "\n",
    "coeff_used_003 = np.sum(lm_elastic.coef_ != 0)\n",
    "\n",
    "print(\"Coefficient used:\",\"\\n\",coeff_used_003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d756ea",
   "metadata": {},
   "source": [
    "Support Vector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6960c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVR(kernel = 'rbf')\n",
    "svm.fit(x_trainsc, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_svm = svm.predict(x_testsc)\n",
    "\n",
    "\n",
    "print(\"Support Vector Model Train Score: \", svm.score(x_trainsc , y_train))\n",
    "\n",
    "print(\"Support Vector Model Test Score: \", svm.score(x_testsc , y_test))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error: \\n', np.round(metrics.mean_absolute_error(y_test, y_pred_svm),2)) \n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print('Mean Squared Error: \\n', np.round(metrics.mean_squared_error(y_test, y_pred_svm),2))\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print('Root Mean Squared Error: \\n', np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_svm)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca979785",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(svm, n_features_to_select=6)             \n",
    "rfe = rfe.fit(x_trainsc, y_train)\n",
    "\n",
    "r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "scores = cross_val_score(rr, x_trainsc, y_train, scoring='r2', cv=5)\n",
    "scores   \n",
    "\n",
    "# create a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "scores = cross_val_score(lasso_001, x_trainsc, y_train, scoring='r2', cv=folds)\n",
    "scores  \n",
    "\n",
    "scores = cross_val_score(lasso_001, x_trainsc, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f127cf",
   "metadata": {},
   "source": [
    "Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d00f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dTree = DecisionTreeRegressor(random_state=1)\n",
    "dTree.fit(x_trainsc, y_train)\n",
    "y_predict = dTree.predict(x_testsc)\n",
    "\n",
    "print(\"Decision Tree Model Train Score: \", dTree.score(x_trainsc , y_train))\n",
    "\n",
    "print(\"Decision Tree Model Test Score: \", dTree.score(x_testsc , y_test))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error: \\n', np.round(metrics.mean_absolute_error(y_test, y_predict),2)) \n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print('Mean Squared Error: \\n', np.round(metrics.mean_squared_error(y_test, y_predict),2))\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print('Root Mean Squared Error: \\n', np.round(np.sqrt(metrics.mean_squared_error(y_test, y_predict)),2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4491f0d",
   "metadata": {},
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb85092",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model= RandomForestRegressor(random_state=1)\n",
    "rf_model.fit(x_trainsc, y_train)\n",
    "rf_model_predict = rf_model.predict(x_testsc)\n",
    "\n",
    "print(\"Random Forest Model Train Score: \", rf_model.score(x_trainsc , y_train))\n",
    "\n",
    "print(\"Random Forest Model Test Score: \", rf_model.score(x_testsc , y_test))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error: \\n', np.round(metrics.mean_absolute_error(y_test, rf_model_predict),2)) \n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print('Mean Squared Error: \\n', np.round(metrics.mean_squared_error(y_test, rf_model_predict),2))\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print('Root Mean Squared Error: \\n', np.round(np.sqrt(metrics.mean_squared_error(y_test, rf_model_predict)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model as a pickle string.\n",
    "saved_model = pickle.dumps(dTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ff897",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "Decision tree model performs the best in these conditions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
